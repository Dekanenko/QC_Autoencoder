{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-FAbzj6GudLa"
      },
      "outputs": [],
      "source": [
        "# !pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "A_eqi5Pzv2pA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qml.about()"
      ],
      "metadata": {
        "id": "noDAiRZc3IfC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions for circuit building (can skip)\n",
        "def data_shape_transform(data, n_qubits=8):\n",
        "  # data = data.detach().numpy()\n",
        "  data = torch.reshape(data, (-1, 1))\n",
        "  out = []\n",
        "  col_num = int(np.ceil(len(data)/n_qubits))\n",
        "  for i in range(n_qubits):\n",
        "    tmp = []\n",
        "    for j in range(col_num):\n",
        "      if i*col_num+j >= len(data):\n",
        "        break\n",
        "\n",
        "      tmp.append(data[i*col_num+j])\n",
        "\n",
        "    out.append(tmp)\n",
        "\n",
        "  # print(out)\n",
        "  return out, len(data)\n",
        "\n",
        "def data_embedding(data, n_qubits=8):\n",
        "  data, data_len = data_shape_transform(data, n_qubits=n_qubits)\n",
        "\n",
        "  flag = 1\n",
        "  col_num = int(np.ceil(data_len/n_qubits))\n",
        "  qml.broadcast(qml.Hadamard, wires=range(n_qubits), pattern=\"single\")\n",
        "\n",
        "  for j in range(col_num):\n",
        "    for i in range(n_qubits):\n",
        "      if i*col_num+j >= data_len:\n",
        "        break\n",
        "\n",
        "      if flag == 1:\n",
        "        qml.RZ(data[i][j], wires=i)\n",
        "      else:\n",
        "        qml.RX(data[i][j], wires=i)\n",
        "\n",
        "    flag *= -1\n",
        "\n",
        "\n",
        "def apply_weights(weights, n_qubits=8):\n",
        "  for i in range(len(weights)):\n",
        "\n",
        "    for j in range(n_qubits):\n",
        "      qml.RZ(weights[i][j], wires=j)\n",
        "\n",
        "    index = j\n",
        "    flag = 1\n",
        "    for k in range(n_qubits):\n",
        "      for j in range(n_qubits):\n",
        "        if k == j:\n",
        "          continue\n",
        "        index += 1\n",
        "        if flag == 1:\n",
        "          qml.CRX(weights[i][index], wires=[k, j])\n",
        "        else:\n",
        "          qml.CRY(weights[i][index], wires=[k, j])\n",
        "\n",
        "      flag *= -1\n",
        "\n",
        "    for j in range(n_qubits):\n",
        "      qml.RZ(weights[i][index+j], wires=j)"
      ],
      "metadata": {
        "id": "9fgHgMBBv-qF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, X in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, X)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, X).item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss\n",
        "\n",
        "def train(model, train_dataloader, epochs, loss_fn, optimizer):\n",
        "    accuracy_hist = []\n",
        "    loss_hist = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "        if epoch % 1 == 0:\n",
        "          print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "          loss = test_loop(train_dataloader, model, loss_fn)\n",
        "          loss_hist.append(loss)\n",
        "\n",
        "    print(\"Finish\")\n",
        "    return accuracy_hist, loss_hist"
      ],
      "metadata": {
        "id": "G_4qYvl2v-yH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 8\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)"
      ],
      "metadata": {
        "id": "5p7jqLhpv-0L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def c1(inputs, weights):\n",
        "  data_embedding(inputs, n_qubits=8)\n",
        "  apply_weights(weights, n_qubits=8)\n",
        "\n",
        "  return qml.probs(wires=range(n_qubits))"
      ],
      "metadata": {
        "id": "iucqH_7rwrpe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Q1Layer(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, circuit=None, n_qubits=8, q_depth=1):\n",
        "        super().__init__()\n",
        "\n",
        "        n_args = (q_depth, n_qubits**2 + n_qubits)\n",
        "        weight_shapes = {\"weights\": n_args}\n",
        "        self.qlayer_1 = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
        "\n",
        "    def forward(self, input_):\n",
        "        q = self.qlayer_1(inputs=input_[0])\n",
        "        q = q.unsqueeze(0)\n",
        "        q = torch.reshape(q, (1, 16, 16))\n",
        "        return q"
      ],
      "metadata": {
        "id": "HfbG4Yerwrri"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 3, stride=1, padding=\"valid\"),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3, stride=1, padding=\"valid\"),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 5, stride=1, padding=\"valid\"),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(in_channels = 8, out_channels = 5, kernel_size = 3, stride=1, padding=\"valid\"),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Flatten(),\n",
        "\n",
        "    Q1Layer(circuit=c1, n_qubits=8, q_depth=3),\n",
        "\n",
        "    torch.nn.Conv2d(in_channels = 1, out_channels = 5, kernel_size = 3, stride=1, padding=\"same\"),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(in_channels = 5, out_channels = 1, kernel_size = 3, stride=1, padding=\"same\"),\n",
        "    torch.nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# model = model.double()\n",
        "\n",
        "# sp = torch.nn.Flatten()\n",
        "# l1 = torch.nn.Linear(256, 180)\n",
        "# f1 = torch.nn.Sigmoid()\n",
        "# ql = Q1Layer(circuit=c1, n_qubits=8, q_depth=1)\n",
        "\n",
        "# model = torch.nn.Sequential(sp, l1, f1, ql)\n",
        "# model.double()"
      ],
      "metadata": {
        "id": "yYfEpTAzwxCi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "LYxSPBtKPA9E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('prepared_dataset.xlsx')\n",
        "data = pd.DataFrame(data).to_numpy()\n",
        "\n",
        "data = np.reshape(data, (len(data), 16, 16))"
      ],
      "metadata": {
        "id": "8wpDUfpqwxJ0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "\n",
        "data = torch.tensor(data, requires_grad=True).float()\n",
        "\n",
        "# data = torch.from_numpy(data)\n",
        "# train_dataloader = DataLoader(torch.from_numpy(data), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "omNIQU1wxS1U"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(data.dtype)\n",
        "# data = data.to(torch.float)\n",
        "# print(data.dtype)"
      ],
      "metadata": {
        "id": "jlqXlgyVK44J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "BwING1VGK8LX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "en0015ZuK8TJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "epochs = 40"
      ],
      "metadata": {
        "id": "31qT3j5CxS3W"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = torch.nn.L1Loss()"
      ],
      "metadata": {
        "id": "1rc-v4muxS5t"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model[6].weight[0])\n",
        "print(model[10].weight[0])\n",
        "before_training_first = model[0].weight\n",
        "before_training_last = model[10].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mluoUCbLxiyq",
        "outputId": "9a869ad8-7b30-4fa0-e892-8b042f78a0dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0300,  0.0243,  0.0611],\n",
            "         [-0.0146,  0.0614, -0.0669],\n",
            "         [ 0.0191,  0.0824,  0.0196]],\n",
            "\n",
            "        [[-0.0410, -0.1106, -0.0152],\n",
            "         [ 0.0852,  0.0899, -0.0119],\n",
            "         [ 0.0423, -0.0329,  0.0295]],\n",
            "\n",
            "        [[ 0.1120,  0.0156, -0.0653],\n",
            "         [-0.0813,  0.0295,  0.1063],\n",
            "         [ 0.0867,  0.0552, -0.0338]],\n",
            "\n",
            "        [[-0.0259,  0.0162,  0.0290],\n",
            "         [ 0.0230, -0.1061, -0.1136],\n",
            "         [-0.0336,  0.0987,  0.0722]],\n",
            "\n",
            "        [[-0.0827,  0.0437, -0.1094],\n",
            "         [-0.1069, -0.0284, -0.0063],\n",
            "         [-0.1106,  0.0981, -0.0094]],\n",
            "\n",
            "        [[ 0.0711, -0.0435, -0.0144],\n",
            "         [-0.0158,  0.0510,  0.0587],\n",
            "         [-0.0635,  0.0498,  0.0874]],\n",
            "\n",
            "        [[-0.0742, -0.0307,  0.0846],\n",
            "         [-0.1017, -0.0080, -0.1011],\n",
            "         [-0.1013,  0.0491, -0.0098]],\n",
            "\n",
            "        [[ 0.0711,  0.0062, -0.0199],\n",
            "         [-0.0842, -0.0533,  0.0265],\n",
            "         [ 0.0129, -0.0614, -0.0996]]], grad_fn=<SelectBackward0>)\n",
            "tensor([[[-0.0479, -0.2080,  0.3233],\n",
            "         [-0.0089,  0.2154, -0.0766],\n",
            "         [ 0.0062,  0.0060,  0.2808]]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0\n",
        "    size = len(train_dataloader)\n",
        "\n",
        "    for x in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_evaluated = loss_fn(model(x), x)\n",
        "        loss_evaluated.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss_evaluated\n",
        "\n",
        "    avg_loss = running_loss/size\n",
        "    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkvRYKEjxi0-",
        "outputId": "f65576e7-6c57-431b-b0c6-e688eb77f23a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss over epoch 1: 0.3186\n",
            "Average loss over epoch 2: 0.2641\n",
            "Average loss over epoch 3: 0.2627\n",
            "Average loss over epoch 4: 0.2627\n",
            "Average loss over epoch 5: 0.2627\n",
            "Average loss over epoch 6: 0.2627\n",
            "Average loss over epoch 7: 0.2627\n",
            "Average loss over epoch 8: 0.2627\n",
            "Average loss over epoch 9: 0.2627\n",
            "Average loss over epoch 10: 0.2627\n",
            "Average loss over epoch 11: 0.2627\n",
            "Average loss over epoch 12: 0.2627\n",
            "Average loss over epoch 13: 0.2627\n",
            "Average loss over epoch 14: 0.2627\n",
            "Average loss over epoch 15: 0.2627\n",
            "Average loss over epoch 16: 0.2627\n",
            "Average loss over epoch 17: 0.2627\n",
            "Average loss over epoch 18: 0.2627\n",
            "Average loss over epoch 19: 0.2627\n",
            "Average loss over epoch 20: 0.2627\n",
            "Average loss over epoch 21: 0.2627\n",
            "Average loss over epoch 22: 0.2627\n",
            "Average loss over epoch 23: 0.2627\n",
            "Average loss over epoch 24: 0.2627\n",
            "Average loss over epoch 25: 0.2627\n",
            "Average loss over epoch 26: 0.2627\n",
            "Average loss over epoch 27: 0.2627\n",
            "Average loss over epoch 28: 0.2627\n",
            "Average loss over epoch 29: 0.2627\n",
            "Average loss over epoch 30: 0.2627\n",
            "Average loss over epoch 31: 0.2627\n",
            "Average loss over epoch 32: 0.2627\n",
            "Average loss over epoch 33: 0.2627\n",
            "Average loss over epoch 34: 0.2627\n",
            "Average loss over epoch 35: 0.2627\n",
            "Average loss over epoch 36: 0.2627\n",
            "Average loss over epoch 37: 0.2627\n",
            "Average loss over epoch 38: 0.2627\n",
            "Average loss over epoch 39: 0.2627\n",
            "Average loss over epoch 40: 0.2627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(train_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koKGC1oJx58b",
        "outputId": "f0d2de54-2e13-440a-89c5-54501918490f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg loss: 0.262657 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2626572012901306"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model[0].weight[0:3])\n",
        "print(model[10].weight[0:3])\n",
        "after_training_first = model[0].weight\n",
        "after_training_last = model[10].weight"
      ],
      "metadata": {
        "id": "maSyQdcK4d-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a9fe6d-e5b4-4450-aad2-bb806e422fc9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.3716, -0.4663, -0.4798],\n",
            "          [-0.0973, -0.1909, -0.6888],\n",
            "          [-0.5084, -0.2886, -0.5322]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0921,  0.6459,  0.4353],\n",
            "          [-0.3653, -0.2966, -0.2284],\n",
            "          [-0.4189, -0.4472, -0.6616]]],\n",
            "\n",
            "\n",
            "        [[[-0.0875,  0.4398, -0.4813],\n",
            "          [-0.5354, -0.3517, -0.4402],\n",
            "          [-0.2684, -0.2001, -0.4975]]]], grad_fn=<SliceBackward0>)\n",
            "tensor([[[[ 1.2003,  0.8362,  1.4726],\n",
            "          [ 1.2676,  1.4912,  1.1225],\n",
            "          [ 1.1384,  1.1684,  1.3969]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0813,  1.3246,  0.8870],\n",
            "          [ 1.0634,  1.1300,  0.8639],\n",
            "          [ 0.6684,  0.8387,  1.0243]]],\n",
            "\n",
            "\n",
            "        [[[-0.5897, -0.8066, -0.4446],\n",
            "          [-0.3155, -0.3791, -0.3083],\n",
            "          [-0.7911, -0.4665, -0.7870]]]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    }
  ]
}